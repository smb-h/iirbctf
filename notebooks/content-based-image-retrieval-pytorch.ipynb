{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Content Based Image Retrieval (CBIR)\n","## Approach:\n","\n","- By observing the data its pretty clear that an Unsupervised alongwith couple of different Hashing approachs will be the most commendable. Although there are number of techniques in that area as well, we'll focus on Hashing and Auto-Encoder techniques:\n","    \n","    - ***Latent Feature Extraction***: In this technique we can find feature vectors for every image by creating hooks on a pre-trained network and extracting the vector from previous layers. Other technique devises the use of **AutoEncoders** where the Latent features can be extracted from Encoder itself. For the sake of this data we'll proceed with AutoEncoders. For the retrieval part we'll look into Euclidean based Search (O(NlogN)) and Hashing Based Approaches (O(logN)).\n","    <br>\n","    - ***Image Hashing Search***: This can be done by:\n","        - Uniquely quantify the contents of an image using only a single integer.\n","        - Find duplicate or near-duplicate images in a dataset of images based on their computed hashes.<br>\n","        <br>\n","      This can be accomplished by a specialized data structure called a **VP-Tree**. Using a VP-Tree we can reduce our search complexity from O(nlogn) to O(log n), enabling us to obtain our sub-linear goal!"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/user01/.virtualenvs/smbh/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import time\n","import copy\n","import pickle\n","from barbar import Bar\n","import numpy as np\n","import pandas as pd\n","import scipy\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","import cv2\n","\n","import torch\n","import torchvision\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import Dataset\n","from torchvision import transforms\n","from torchsummary import summary\n","\n","from tqdm import tqdm\n","# from tqdm.notebook import tqdm\n","from pathlib import Path\n","import gc\n","import os\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["RANDOMSTATE = 0\n"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["# Find if any accelerator is presented, if yes switch device to use CUDA or else use CPU\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(100, 1)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>dataset/1123.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>dataset/998.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>dataset/2882.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dataset/2548.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>dataset/3026.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              image\n","0  dataset/1123.jpg\n","1   dataset/998.jpg\n","2  dataset/2882.jpg\n","3  dataset/2548.jpg\n","4  dataset/3026.jpg"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# preparing intermediate DataFrame\n","dataset_path = Path('./dataset/')\n","df = pd.DataFrame()\n","\n","df['image'] = [f for f in os.listdir(dataset_path) if os.path.isfile(os.path.join(dataset_path, f))]\n","df['image'] = df['image'].apply(lambda x: dataset_path / x)\n","# filter to first 100 images\n","df = df[:100]\n","\n","print(df.shape)\n","df.head()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preparation"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["class CBIRDataset(Dataset):\n","    def __init__(self, df):\n","        self.df = df\n","        \n","        self.transformations = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","        ])\n","    \n","    def __getitem__(self, key):\n","        if isinstance(key, slice):\n","            raise NotImplementedError('slicing is not supported')\n","        \n","        row = self.df.iloc[key]\n","        image = self.transformations(Image.open(row['image']))\n","        return image\n","    \n","    def __len__(self):\n","        return len(self.df.index)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["# Intermediate Function to process data from the data retrival class\n","def prepare_data(df):\n","    train_df, validate_df = train_test_split(df, test_size=0.15, random_state=RANDOMSTATE)\n","    train_set = CBIRDataset(train_df)\n","    validate_set = CBIRDataset(validate_df)\n","    \n","    return train_set, validate_set\n"]},{"cell_type":"markdown","metadata":{},"source":["# AutoEncoder Model"]},{"cell_type":"markdown","metadata":{},"source":["## High Level Structure of an AutoEncoder"]},{"cell_type":"markdown","metadata":{},"source":["![](https://hackernoon.com/hn-images/1*op0VO_QK4vMtCnXtmigDhA.png)"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["class ConvAutoencoder(nn.Module):\n","    def __init__(self):\n","        super(ConvAutoencoder, self).__init__()\n","        # in (N,3,512,512)\n","        self.encoder = nn.Sequential(\n","            # (32, 16, 171, 171)\n","            nn.Conv2d(in_channels=3, \n","                      out_channels=16, \n","                      kernel_size=(3,3), \n","                      stride=3, \n","                      padding=1),  \n","            nn.ReLU(True),\n","            # (N, 16, 85, 85)\n","            nn.MaxPool2d(2, stride=2),  \n","            # (N, 8, 43, 43)\n","            nn.Conv2d(in_channels=16, \n","                      out_channels=8, \n","                      kernel_size=(3,3), \n","                      stride=2, \n","                      padding=1),  \n","            nn.ReLU(True),\n","            # (N, 8, 42, 42)\n","            nn.MaxPool2d(2, stride=1)  \n","        )\n","        self.decoder = nn.Sequential(\n","            # (N, 16, 85, 85)\n","            nn.ConvTranspose2d(in_channels = 8, \n","                               out_channels=16, \n","                               kernel_size=(3,3), \n","                               stride=2),  \n","            nn.ReLU(True),\n","            # (N, 8, 255, 255)\n","            nn.ConvTranspose2d(in_channels=16, \n","                               out_channels=8, \n","                               kernel_size=(5,5), \n","                               stride=3, \n","                               padding=1),  \n","            nn.ReLU(True),\n","            # (N, 3, 512, 512)\n","            nn.ConvTranspose2d(in_channels=8, \n","                               out_channels=3, \n","                               kernel_size=(6,6), \n","                               stride=2, \n","                               padding=1),  \n","            nn.Tanh()\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["class ConvAutoencoder_v2(nn.Module):\n","    def __init__(self):\n","        super(ConvAutoencoder_v2, self).__init__()\n","        # in (N,3,512,512)\n","        self.encoder = nn.Sequential(\n","            \n","            nn.Conv2d(in_channels=3, \n","                      out_channels=64, \n","                      kernel_size=(3,3), \n","                      stride=1, \n","                      padding=1),\n","            nn.ReLU(True),\n","            nn.Conv2d(in_channels=64, \n","                      out_channels=64, \n","                      kernel_size=(3,3), \n","                      stride=1, \n","                      padding=1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=2), \n","            \n","            nn.Conv2d(in_channels=64, \n","                      out_channels=128, \n","                      kernel_size=(3,3), \n","                      stride=2, \n","                      padding=1),\n","            nn.ReLU(True),\n","            nn.Conv2d(in_channels=128, \n","                      out_channels=128, \n","                      kernel_size=(3,3), \n","                      stride=1, \n","                      padding=0), \n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=2), \n","            \n","            nn.Conv2d(in_channels=128, \n","                      out_channels=256, \n","                      kernel_size=(3,3), \n","                      stride=2, \n","                      padding=1), \n","            nn.ReLU(True),\n","            nn.Conv2d(in_channels=256, \n","                      out_channels=256, \n","                      kernel_size=(3,3), \n","                      stride=1, \n","                      padding=1), \n","            nn.ReLU(True),\n","            nn.Conv2d(in_channels=256, \n","                      out_channels=256, \n","                      kernel_size=(3,3), \n","                      stride=1, \n","                      padding=1), \n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=2) \n","        )\n","        self.decoder = nn.Sequential(\n","            \n","            nn.ConvTranspose2d(in_channels = 256, \n","                               out_channels=256, \n","                               kernel_size=(3,3), \n","                               stride=1,\n","                              padding=1), \n"," \n","            nn.ConvTranspose2d(in_channels=256, \n","                               out_channels=256, \n","                               kernel_size=(3,3), \n","                               stride=1, \n","                               padding=1),  \n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(in_channels=256, \n","                               out_channels=128, \n","                               kernel_size=(3,3), \n","                               stride=2, \n","                               padding=0),  \n","            \n","            nn.ConvTranspose2d(in_channels=128, \n","                               out_channels=64, \n","                               kernel_size=(3,3), \n","                               stride=2, \n","                               padding=1),  \n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(in_channels=64, \n","                               out_channels=32, \n","                               kernel_size=(3,3), \n","                               stride=2, \n","                               padding=1), \n","            \n","            nn.ConvTranspose2d(in_channels=32, \n","                               out_channels=32, \n","                               kernel_size=(3,3), \n","                               stride=2, \n","                               padding=1),  \n","            nn.ReLU(True),\n","            \n","            nn.ConvTranspose2d(in_channels=32, \n","                               out_channels=3, \n","                               kernel_size=(4,4), \n","                               stride=2, \n","                               padding=2),  \n","            nn.Tanh()\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 512, 512]           1,792\n","              ReLU-2         [-1, 64, 512, 512]               0\n","            Conv2d-3         [-1, 64, 512, 512]          36,928\n","              ReLU-4         [-1, 64, 512, 512]               0\n","         MaxPool2d-5         [-1, 64, 256, 256]               0\n","            Conv2d-6        [-1, 128, 128, 128]          73,856\n","              ReLU-7        [-1, 128, 128, 128]               0\n","            Conv2d-8        [-1, 128, 126, 126]         147,584\n","              ReLU-9        [-1, 128, 126, 126]               0\n","        MaxPool2d-10          [-1, 128, 63, 63]               0\n","           Conv2d-11          [-1, 256, 32, 32]         295,168\n","             ReLU-12          [-1, 256, 32, 32]               0\n","           Conv2d-13          [-1, 256, 32, 32]         590,080\n","             ReLU-14          [-1, 256, 32, 32]               0\n","           Conv2d-15          [-1, 256, 32, 32]         590,080\n","             ReLU-16          [-1, 256, 32, 32]               0\n","        MaxPool2d-17          [-1, 256, 16, 16]               0\n","  ConvTranspose2d-18          [-1, 256, 16, 16]         590,080\n","  ConvTranspose2d-19          [-1, 256, 16, 16]         590,080\n","             ReLU-20          [-1, 256, 16, 16]               0\n","  ConvTranspose2d-21          [-1, 128, 33, 33]         295,040\n","  ConvTranspose2d-22           [-1, 64, 65, 65]          73,792\n","             ReLU-23           [-1, 64, 65, 65]               0\n","  ConvTranspose2d-24         [-1, 32, 129, 129]          18,464\n","  ConvTranspose2d-25         [-1, 32, 257, 257]           9,248\n","             ReLU-26         [-1, 32, 257, 257]               0\n","  ConvTranspose2d-27          [-1, 3, 512, 512]           1,539\n","             Tanh-28          [-1, 3, 512, 512]               0\n","================================================================\n","Total params: 3,313,731\n","Trainable params: 3,313,731\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 3.00\n","Forward/backward pass size (MB): 678.39\n","Params size (MB): 12.64\n","Estimated Total Size (MB): 694.03\n","----------------------------------------------------------------\n"]}],"source":["summary(ConvAutoencoder_v2().to(device),(3, 512, 512))\n"]},{"cell_type":"markdown","metadata":{},"source":["# Training Function"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["def load_ckpt(checkpoint_path, model, optimizer):\n","    \n","    # load check point\n","    checkpoint = torch.load(checkpoint_path)\n","\n","    # initialize state_dict from checkpoint to model\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    # initialize optimizer from checkpoint to optimizer\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","    # initialize valid_loss_min from checkpoint to valid_loss_min\n","    #valid_loss_min = checkpoint['valid_loss_min']\n","\n","    # return model, optimizer, epoch value, min validation loss \n","    return model, optimizer, checkpoint['epoch']\n","\n","def save_checkpoint(state, filename):\n","    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n","    print (\"=> Saving a new best\")\n","    torch.save(state, filename)  # save checkpoint\n","    \n","def train_model(model,  \n","                criterion, \n","                optimizer, \n","                #scheduler, \n","                num_epochs):\n","    since = time.time()\n","    \n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_loss = np.inf\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","\n","            # Iterate over data.\n","            for idx,inputs in enumerate(Bar(dataloaders[phase])):\n","                inputs = inputs.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, inputs)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","            #if phase == 'train':\n","            #    scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","\n","            print('{} Loss: {:.4f}'.format(\n","                phase, epoch_loss))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_loss < best_loss:\n","                best_loss = epoch_loss\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","                save_checkpoint(state={   \n","                                    'epoch': epoch,\n","                                    'state_dict': model.state_dict(),\n","                                    'best_loss': best_loss,\n","                                    'optimizer_state_dict':optimizer.state_dict()\n","                                },filename='ckpt_epoch_{}.pt'.format(epoch))\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Loss: {:4f}'.format(best_loss))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, optimizer, epoch_loss\n"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["EPOCHS = 150\n","NUM_BATCHES = 32\n","RETRAIN = False\n","\n","train_set, validate_set = prepare_data(df)\n","\n","dataloaders = {'train': DataLoader(train_set, batch_size=NUM_BATCHES, shuffle=True, num_workers=1) ,\n","                'val':DataLoader(validate_set, batch_size=NUM_BATCHES, num_workers=1)\n","                }\n","\n","dataset_sizes = {'train': len(train_set),'val':len(validate_set)}\n","\n","model = ConvAutoencoder_v2().to(device)\n","\n","criterion = nn.MSELoss()\n","# Observe that all parameters are being optimized\n","optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n","# Decay LR by a factor of 0.1 every 7 epochs\n","#exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"ename":"KeyError","evalue":"'model_state_dict'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# If re-training is required:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Load the old model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# if RETRAIN == True:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[39m# load the saved checkpoint\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model, optimizer, start_epoch \u001b[39m=\u001b[39m load_ckpt(\u001b[39m'\u001b[39;49m\u001b[39m./ckpt_epoch_148.pt\u001b[39;49m\u001b[39m'\u001b[39;49m, model, optimizer)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCheckpoint Loaded\u001b[39m\u001b[39m'\u001b[39m)\n","Cell \u001b[0;32mIn[11], line 7\u001b[0m, in \u001b[0;36mload_ckpt\u001b[0;34m(checkpoint_path, model, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(checkpoint_path)\n\u001b[1;32m      6\u001b[0m \u001b[39m# initialize state_dict from checkpoint to model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39;49m\u001b[39mmodel_state_dict\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      9\u001b[0m \u001b[39m# initialize optimizer from checkpoint to optimizer\u001b[39;00m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39moptimizer_state_dict\u001b[39m\u001b[39m'\u001b[39m])\n","\u001b[0;31mKeyError\u001b[0m: 'model_state_dict'"]}],"source":["# If re-training is required:\n","# Load the old model\n","if RETRAIN == True:\n","    # load the saved checkpoint\n","    model, optimizer, start_epoch = load_ckpt('../input/cbirpretrained/conv_autoencoder.pt', model, optimizer)\n","    print('Checkpoint Loaded')\n"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0/150\n","----------\n","85/85: [=====================>..........] - ETA 1.2s\n","train Loss: 0.2271\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.2303\n","=> Saving a new best\n","\n","Epoch 1/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.2264\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.2292\n","=> Saving a new best\n","\n","Epoch 2/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.2256\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.2257\n","=> Saving a new best\n","\n","Epoch 3/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.2245\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.2183\n","=> Saving a new best\n","\n","Epoch 4/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.2201\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.2221\n","\n","Epoch 5/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.2208\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.2175\n","=> Saving a new best\n","\n","Epoch 6/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.2138\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1980\n","=> Saving a new best\n","\n","Epoch 7/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.2031\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1868\n","=> Saving a new best\n","\n","Epoch 8/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1900\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1724\n","=> Saving a new best\n","\n","Epoch 9/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1800\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1583\n","=> Saving a new best\n","\n","Epoch 10/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1740\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1513\n","=> Saving a new best\n","\n","Epoch 11/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1678\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1455\n","=> Saving a new best\n","\n","Epoch 12/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1633\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1405\n","=> Saving a new best\n","\n","Epoch 13/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.1587\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1332\n","=> Saving a new best\n","\n","Epoch 14/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1530\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1288\n","=> Saving a new best\n","\n","Epoch 15/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1493\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1281\n","=> Saving a new best\n","\n","Epoch 16/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1487\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1226\n","=> Saving a new best\n","\n","Epoch 17/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1450\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1198\n","=> Saving a new best\n","\n","Epoch 18/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1423\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1169\n","=> Saving a new best\n","\n","Epoch 19/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1395\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1146\n","=> Saving a new best\n","\n","Epoch 20/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1365\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1118\n","=> Saving a new best\n","\n","Epoch 21/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1323\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1070\n","=> Saving a new best\n","\n","Epoch 22/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1254\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.1026\n","=> Saving a new best\n","\n","Epoch 23/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1183\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0996\n","=> Saving a new best\n","\n","Epoch 24/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1135\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0942\n","=> Saving a new best\n","\n","Epoch 25/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.1056\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0904\n","=> Saving a new best\n","\n","Epoch 26/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.1001\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0893\n","=> Saving a new best\n","\n","Epoch 27/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0950\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0868\n","=> Saving a new best\n","\n","Epoch 28/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0911\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0840\n","=> Saving a new best\n","\n","Epoch 29/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0883\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0818\n","=> Saving a new best\n","\n","Epoch 30/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0863\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0814\n","=> Saving a new best\n","\n","Epoch 31/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0856\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0814\n","=> Saving a new best\n","\n","Epoch 32/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0856\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0799\n","=> Saving a new best\n","\n","Epoch 33/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0844\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0795\n","=> Saving a new best\n","\n","Epoch 34/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0838\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0800\n","\n","Epoch 35/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0829\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0809\n","\n","Epoch 36/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0833\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0775\n","=> Saving a new best\n","\n","Epoch 37/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0815\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0767\n","=> Saving a new best\n","\n","Epoch 38/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0810\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0776\n","\n","Epoch 39/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0807\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0769\n","\n","Epoch 40/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0802\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0758\n","=> Saving a new best\n","\n","Epoch 41/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0795\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0763\n","\n","Epoch 42/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0794\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0742\n","=> Saving a new best\n","\n","Epoch 43/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0781\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0745\n","\n","Epoch 44/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0780\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0727\n","=> Saving a new best\n","\n","Epoch 45/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0771\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0722\n","=> Saving a new best\n","\n","Epoch 46/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0763\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0721\n","=> Saving a new best\n","\n","Epoch 47/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0767\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0710\n","=> Saving a new best\n","\n","Epoch 48/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0753\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0712\n","\n","Epoch 49/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0754\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0696\n","=> Saving a new best\n","\n","Epoch 50/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0741\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0696\n","=> Saving a new best\n","\n","Epoch 51/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0740\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0695\n","=> Saving a new best\n","\n","Epoch 52/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0734\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0697\n","\n","Epoch 53/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0733\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0679\n","=> Saving a new best\n","\n","Epoch 54/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0725\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0673\n","=> Saving a new best\n","\n","Epoch 55/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0717\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0675\n","\n","Epoch 56/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0713\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0664\n","=> Saving a new best\n","\n","Epoch 57/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0709\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0684\n","\n","Epoch 58/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0713\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0660\n","=> Saving a new best\n","\n","Epoch 59/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0710\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0653\n","=> Saving a new best\n","\n","Epoch 60/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0716\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0659\n","\n","Epoch 61/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0734\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0663\n","\n","Epoch 62/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0722\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0707\n","\n","Epoch 63/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0715\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0665\n","\n","Epoch 64/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0705\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0645\n","=> Saving a new best\n","\n","Epoch 65/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0695\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0666\n","\n","Epoch 66/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0692\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0640\n","=> Saving a new best\n","\n","Epoch 67/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0687\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0655\n","\n","Epoch 68/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0684\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0631\n","=> Saving a new best\n","\n","Epoch 69/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0674\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0637\n","\n","Epoch 70/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0676\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0634\n","\n","Epoch 71/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0672\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0621\n","=> Saving a new best\n","\n","Epoch 72/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0666\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0630\n","\n","Epoch 73/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0664\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0623\n","\n","Epoch 74/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0662\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0616\n","=> Saving a new best\n","\n","Epoch 75/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0657\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0611\n","=> Saving a new best\n","\n","Epoch 76/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0655\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0613\n","\n","Epoch 77/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0653\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0610\n","=> Saving a new best\n","\n","Epoch 78/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0650\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0606\n","=> Saving a new best\n","\n","Epoch 79/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0648\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0609\n","\n","Epoch 80/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0647\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0601\n","=> Saving a new best\n","\n","Epoch 81/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0642\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0599\n","=> Saving a new best\n","\n","Epoch 82/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0640\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0600\n","\n","Epoch 83/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0639\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0597\n","=> Saving a new best\n","\n","Epoch 84/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0636\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0594\n","=> Saving a new best\n","\n","Epoch 85/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0633\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0592\n","=> Saving a new best\n","\n","Epoch 86/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0630\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0589\n","=> Saving a new best\n","\n","Epoch 87/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0630\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0586\n","=> Saving a new best\n","\n","Epoch 88/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0627\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0586\n","\n","Epoch 89/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0626\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0585\n","=> Saving a new best\n","\n","Epoch 90/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0626\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0582\n","=> Saving a new best\n","\n","Epoch 91/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0620\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0579\n","=> Saving a new best\n","\n","Epoch 92/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0617\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0576\n","=> Saving a new best\n","\n","Epoch 93/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0616\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0574\n","=> Saving a new best\n","\n","Epoch 94/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0613\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0579\n","\n","Epoch 95/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0625\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0589\n","\n","Epoch 96/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0619\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0582\n","\n","Epoch 97/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0616\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0580\n","\n","Epoch 98/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0613\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0574\n","=> Saving a new best\n","\n","Epoch 99/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0608\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0573\n","=> Saving a new best\n","\n","Epoch 100/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0608\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0572\n","=> Saving a new best\n","\n","Epoch 101/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0607\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0572\n","=> Saving a new best\n","\n","Epoch 102/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0606\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0565\n","=> Saving a new best\n","\n","Epoch 103/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0603\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0559\n","=> Saving a new best\n","\n","Epoch 104/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0598\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0558\n","=> Saving a new best\n","\n","Epoch 105/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0596\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0557\n","=> Saving a new best\n","\n","Epoch 106/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0594\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0556\n","=> Saving a new best\n","\n","Epoch 107/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0592\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0556\n","\n","Epoch 108/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0592\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0553\n","=> Saving a new best\n","\n","Epoch 109/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0589\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0549\n","=> Saving a new best\n","\n","Epoch 110/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0587\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0548\n","=> Saving a new best\n","\n","Epoch 111/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0586\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0547\n","=> Saving a new best\n","\n","Epoch 112/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0584\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0546\n","=> Saving a new best\n","\n","Epoch 113/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0586\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0567\n","\n","Epoch 114/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0607\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0547\n","\n","Epoch 115/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0591\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0548\n","\n","Epoch 116/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0589\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0546\n","=> Saving a new best\n","\n","Epoch 117/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0588\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0545\n","=> Saving a new best\n","\n","Epoch 118/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0583\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0552\n","\n","Epoch 119/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0590\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0558\n","\n","Epoch 120/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0591\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0568\n","\n","Epoch 121/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0595\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0567\n","\n","Epoch 122/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0590\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0556\n","\n","Epoch 123/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0594\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0549\n","\n","Epoch 124/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0587\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0557\n","\n","Epoch 125/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0586\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0558\n","\n","Epoch 126/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0581\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0542\n","=> Saving a new best\n","\n","Epoch 127/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0575\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0536\n","=> Saving a new best\n","\n","Epoch 128/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0571\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0541\n","\n","Epoch 129/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0571\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0538\n","\n","Epoch 130/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0568\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0536\n","=> Saving a new best\n","\n","Epoch 131/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0567\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0532\n","=> Saving a new best\n","\n","Epoch 132/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0566\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0536\n","\n","Epoch 133/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0564\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0533\n","\n","Epoch 134/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0564\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0529\n","=> Saving a new best\n","\n","Epoch 135/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0561\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0529\n","=> Saving a new best\n","\n","Epoch 136/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0560\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0527\n","=> Saving a new best\n","\n","Epoch 137/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0559\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0527\n","=> Saving a new best\n","\n","Epoch 138/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0558\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0529\n","\n","Epoch 139/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0557\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0525\n","=> Saving a new best\n","\n","Epoch 140/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0554\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0524\n","=> Saving a new best\n","\n","Epoch 141/150\n","----------\n","85/85: [=====================>..........] - ETA 1.0s\n","train Loss: 0.0553\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0524\n","=> Saving a new best\n","\n","Epoch 142/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0552\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0522\n","=> Saving a new best\n","\n","Epoch 143/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0550\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0521\n","=> Saving a new best\n","\n","Epoch 144/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0550\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0521\n","=> Saving a new best\n","\n","Epoch 145/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0548\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0520\n","=> Saving a new best\n","\n","Epoch 146/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0547\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0520\n","=> Saving a new best\n","\n","Epoch 147/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0547\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0520\n","=> Saving a new best\n","\n","Epoch 148/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0544\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0514\n","=> Saving a new best\n","\n","Epoch 149/150\n","----------\n","85/85: [=====================>..........] - ETA 0.9s\n","train Loss: 0.0543\n","15/15: [>...............................] - ETA 0.0s\n","val Loss: 0.0519\n","\n","Training complete in 6m 22s\n","Best val Loss: 0.051446\n"]}],"source":["model, optimizer, loss = train_model(model=model, \n","                    criterion=criterion, \n","                    optimizer=optimizer, \n","                    #scheduler=exp_lr_scheduler,\n","                    num_epochs=EPOCHS)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["# Save the Trained Model\n","torch.save({\n","            'epoch': EPOCHS,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': loss,\n","            }, 'conv_autoencoderv2_200ep.pt')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Inference"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Indexing"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["transformations = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","        ])\n"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["ConvAutoencoder_v2(\n","  (encoder): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (decoder): Sequential(\n","    (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (2): ReLU(inplace=True)\n","    (3): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2))\n","    (4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (5): ReLU(inplace=True)\n","    (6): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (7): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n","    (10): Tanh()\n","  )\n",")"]},"execution_count":15,"metadata":{},"output_type":"execute_result"},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["# Load Model in Evaluation phase\n","model = ConvAutoencoder_v2().to(device)\n","model.load_state_dict(torch.load('./conv_autoencoderv2_200ep.pt', map_location=device)['model_state_dict'], strict=False)\n","\n","model.eval()\n"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["def get_latent_features(images, transformations):\n","    \n","    latent_features = np.zeros((4738,256,16,16))\n","    #latent_features = np.zeros((4738,8,42,42))\n","    \n","    for i,image in enumerate(tqdm(images)):\n","        tensor = transformations(Image.open(image)).to(device)\n","        latent_features[i] = model.encoder(tensor.unsqueeze(0)).cpu().detach().numpy()\n","        \n","    del tensor\n","    gc.collect()\n","    return latent_features\n"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","\u001b[A\n","\u001b[A\n","\u001b[A\n","\u001b[A\n","\u001b[A\n","\u001b[A\n","\u001b[A\n","\u001b[A\n","\u001b[A\n","\u001b[A\n","\u001b[A\n","100%|██████████| 100/100 [00:01<00:00, 76.52it/s]\n","Exception ignored in: <function tqdm.__del__ at 0x7f6027737b80>\n","Traceback (most recent call last):\n","  File \"/home/user01/.virtualenvs/smbh/lib/python3.8/site-packages/tqdm/std.py\", line 1162, in __del__\n","    self.close()\n","  File \"/home/user01/.virtualenvs/smbh/lib/python3.8/site-packages/tqdm/notebook.py\", line 288, in close\n","    self.disp(bar_style='danger', check_delay=False)\n","AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"]}],"source":["images = df.image.values\n","latent_features = get_latent_features(images, transformations)\n"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[],"source":["indexes = list(range(0, 4738))\n","feature_dict = dict(zip(indexes,latent_features))\n","index_dict = {'indexes':indexes,'features':latent_features}\n"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[],"source":["# write the data dictionary to disk\n","with open('features.pkl', \"wb\") as f:\n","   f.write(pickle.dumps(index_dict))\n"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Image Retrieval "]},{"cell_type":"markdown","metadata":{},"source":["<font size=\"3\"> This will be approached with two ways as discussed in the start:\n","    - Euclidean Search:\n","        - Identifying the Latent Features\n","        - Calculating the Euclidean Distance between them\n","        - Returning the closest N indexes (of images)\n","    \n","    - Locality Sensitive Hashing\n","        - Create hashes of the feature vector from Encoder\n","        - Store it in a Hashing Table\n","        - Identify closest images based on hamming distance"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1 Euclidean Search Method"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[],"source":["def euclidean(a, b):\n","    # compute and return the euclidean distance between two vectors\n","    return np.linalg.norm(a - b)\n"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[],"source":["def cosine_distance(a,b):\n","    return scipy.spatial.distance.cosine(a, b)\n"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[],"source":["def perform_search(queryFeatures, index, maxResults=64):\n","\n","    results = []\n","\n","    for i in range(0, len(index[\"features\"])):\n","        # compute the euclidean distance between our query features\n","        # and the features for the current image in our index, then\n","        # update our results list with a 2-tuple consisting of the\n","        # computed distance and the index of the image\n","        d = euclidean(queryFeatures, index[\"features\"][i])\n","        results.append((d, i))\n","    \n","    # sort the results and grab the top ones\n","    results = sorted(results)[:maxResults]\n","    # return the list of results\n","    return results\n"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[],"source":["def build_montages(image_list, image_shape, montage_shape):\n","\n","    if len(image_shape) != 2:\n","        raise Exception('image shape must be list or tuple of length 2 (rows, cols)')\n","    if len(montage_shape) != 2:\n","        raise Exception('montage shape must be list or tuple of length 2 (rows, cols)')\n","    image_montages = []\n","    # start with black canvas to draw images onto\n","    montage_image = np.zeros(shape=(image_shape[1] * (montage_shape[1]), image_shape[0] * montage_shape[0], 3),\n","                          dtype=np.uint8)\n","    cursor_pos = [0, 0]\n","    start_new_img = False\n","    for img in image_list:\n","        if type(img).__module__ != np.__name__:\n","            raise Exception('input of type {} is not a valid numpy array'.format(type(img)))\n","        start_new_img = False\n","        img = cv2.resize(img, image_shape)\n","        # draw image to black canvas\n","        montage_image[cursor_pos[1]:cursor_pos[1] + image_shape[1], cursor_pos[0]:cursor_pos[0] + image_shape[0]] = img\n","        cursor_pos[0] += image_shape[0]  # increment cursor x position\n","        if cursor_pos[0] >= montage_shape[0] * image_shape[0]:\n","            cursor_pos[1] += image_shape[1]  # increment cursor y position\n","            cursor_pos[0] = 0\n","            if cursor_pos[1] >= montage_shape[1] * image_shape[1]:\n","                cursor_pos = [0, 0]\n","                image_montages.append(montage_image)\n","                # reset black canvas\n","                montage_image = np.zeros(shape=(image_shape[1] * (montage_shape[1]), image_shape[0] * montage_shape[0], 3),\n","                                      dtype=np.uint8)\n","                start_new_img = True\n","    if start_new_img is False:\n","        image_montages.append(montage_image)  # add unfinished montage\n","    return image_montages\n"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[(0.0, 100), (0.0, 101), (0.0, 102), (0.0, 103), (0.0, 104), (0.0, 105), (0.0, 106), (0.0, 107), (0.0, 108), (0.0, 109)]\n","(0.0, 100)\n"]},{"ename":"IndexError","evalue":"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[37], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m results:\n\u001b[1;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(i)\n\u001b[0;32m---> 18\u001b[0m     img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(Image\u001b[39m.\u001b[39mopen(images[i][\u001b[39m1\u001b[39m]))\n\u001b[1;32m     19\u001b[0m \u001b[39m#     print(j)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m#     imgs.append(img)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m# montage = build_montages(imgs, (512, 512), (5, 2))[0]\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m# ax[1].imshow(montage)\u001b[39;00m\n","\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"]},{"data":{"image/png":"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","text/plain":["<Figure size 1500x1500 with 2 Axes>"]},"metadata":{},"output_type":"display_data"},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["# take the features for the current image, find all similar\n","# images in our dataset, and then initialize our list of result\n","# images\n","fig, ax = plt.subplots(nrows=2,figsize=(15,15))\n","# Input Index for which images \n","queryIdx = 3166 \n","MAX_RESULTS = 10\n","\n","\n","queryFeatures = latent_features[queryIdx]\n","results = perform_search(queryFeatures, index_dict, maxResults=MAX_RESULTS)\n","print(results)\n","imgs = []\n","\n","# loop over the results\n","for i in results:\n","    print(i)\n","    img = np.array(Image.open(images[i][1]))\n","#     print(j)\n","#     imgs.append(img)\n","\n","# # display the query image\n","# ax[0].imshow(np.array(Image.open(images[queryIdx])))\n","\n","# # build a montage from the results and display it\n","# montage = build_montages(imgs, (512, 512), (5, 2))[0]\n","# ax[1].imshow(montage)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["testpath = Path('../input/testcbir/Test_Images')\n","testdf = pd.DataFrame()\n","\n","testdf['image'] = [f for f in os.listdir(testpath) if os.path.isfile(os.path.join(testpath, f))]\n","testdf['image'] = '../input/testcbir/Test_Images/' + testdf['image'].astype(str)\n","\n","testdf.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["testimages = testdf.image.values\n","test_latent_features = get_latent_features(testimages, transformations)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_latent_features.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig, ax = plt.subplots(nrows=2,figsize=(15,15))\n","MAX_RESULTS = 10\n","queryIdx = 12\n","\n","queryFeatures = test_latent_features[queryIdx]\n","results = perform_search(queryFeatures, index_dict, maxResults=MAX_RESULTS)\n","imgs = []\n","\n","# loop over the results\n","for (d, j) in results:\n","    img = np.array(Image.open(images[j]))\n","    print(j)\n","    imgs.append(img)\n","\n","# display the query image\n","ax[0].imshow(np.array(Image.open(testimages[queryIdx])))\n","\n","# build a montage from the results and display it\n","montage = build_montages(imgs, (512, 512), (5, 2))[0]\n","ax[1].imshow(montage)"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2 LSHashing Method"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#!pip install lshashpy3"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#from lshashpy3 import LSHash"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["## Locality Sensitive Hashing\n","# params\n","# k = 12 # hash size\n","# L = 5  # number of tables\n","# d = 14112 # Dimension of Feature vector\n","# lsh = LSHash(hash_size=k, input_dim=d, num_hashtables=L)\n","\n","# # LSH on all the images\n","# for idx,vec in tqdm(feature_dict.items()):\n","#     lsh.index(vec.flatten(), extra_data=idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["## Exporting as pickle\n","#pickle.dump(lsh, open('lsh.p', \"wb\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# def get_similar_item(idx, feature_dict, lsh_variable, n_items=10):\n","#     response = lsh_variable.query(feature_dict[list(feature_dict.keys())[idx]].flatten(), \n","#                      num_results=n_items+1, distance_func='hamming')\n","    \n","#     imgs = []\n","#     for i in range(1, n_items+1):\n","#         imgs.append(np.array(Image.open(images[response[i][0][1]])))\n","#     return imgs"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# fig, ax = plt.subplots(nrows=2,figsize=(15,15))\n","# queryIdx = 5\n","\n","# ax[0].imshow(np.array(Image.open(images[queryIdx])))\n","\n","# montage = build_montages(get_similar_item(queryIdx, feature_dict, lsh,10),(512, 512), (5, 2))[0]\n","# ax[1].imshow(montage)"]},{"cell_type":"markdown","metadata":{},"source":["# End Notes\n","\n","- We started with the approach of AutoEncoders for Image Latent Features extraction followed by Image retrieval using Euclidean Distance which was an O(NlogN) approach (Time-Complexity) to Hashing which gave us an ~O(logN) approach\n","\n","- Another approach was to use Hashing on features obtained from SIFT, SURF, OBS and building the VP Trees ans search the images in it."]},{"cell_type":"markdown","metadata":{},"source":["![](https://www.pyimagesearch.com/wp-content/uploads/2019/08/image_hashing_search_engine_steps.png)"]},{"cell_type":"markdown","metadata":{},"source":["# Clustering of Images"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.cluster import KMeans, MiniBatchKMeans\n","from scipy.spatial.distance import cdist\n","from sklearn.metrics import silhouette_samples, silhouette_score\n","\n","import matplotlib.cm as cm\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_latent_features1D(images, transformations):\n","    \n","    latent_features1d = []\n","    \n","    for i,image in enumerate(tqdm(images)):\n","        tensor = transformations(Image.open(image)).to(device)\n","        latent_features1d.append(model.encoder(tensor.unsqueeze(0)).cpu().detach().numpy().flatten())\n","        \n","    del tensor\n","    gc.collect()\n","    return latent_features1d"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["images = df.image.values\n","latent_features1d = get_latent_features1D(images, transformations)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["latent_features1d = np.array(latent_features1d)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["distortions = [] \n","inertias = [] \n","mapping1 = {} \n","mapping2 = {} \n","K = range(4,10) \n","  \n","for k in tqdm(K): \n","    #Building and fitting the model \n","    kmeanModel = KMeans(n_clusters=k).fit(latent_features1d)      \n","      \n","    distortions.append(sum(np.min(cdist(latent_features1d, kmeanModel.cluster_centers_, \n","                      'euclidean'),axis=1)) / latent_features1d.shape[0]) \n","    inertias.append(kmeanModel.inertia_) \n","  \n","    mapping1[k] = sum(np.min(cdist(latent_features1d, kmeanModel.cluster_centers_, \n","                 'euclidean'),axis=1)) / latent_features1d.shape[0] \n","    mapping2[k] = kmeanModel.inertia_ "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.plot(K, distortions, 'bx-') \n","plt.xlabel('Values of K') \n","plt.ylabel('Distortion') \n","plt.title('The Elbow Method using Distortion') \n","plt.show() "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X = np.array(latent_features1d)\n","K = range(3,10) \n","\n","for n_clusters in tqdm(K):\n","    # Create a subplot with 1 row and 2 columns\n","    fig, (ax1, ax2) = plt.subplots(1, 2)\n","    fig.set_size_inches(18, 7)\n","\n","    # The 1st subplot is the silhouette plot\n","    # The silhouette coefficient can range from -1, 1 but in this example all\n","    # lie within [-0.1, 1]\n","    ax1.set_xlim([-0.1, 1])\n","    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n","    # plots of individual clusters, to demarcate them clearly.\n","    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n","\n","    # Initialize the clusterer with n_clusters value and a random generator\n","    # seed of 10 for reproducibility.\n","    clusterer = KMeans(n_clusters=n_clusters, random_state=RANDOMSTATE)\n","    cluster_labels = clusterer.fit_predict(X)\n","\n","    # The silhouette_score gives the average value for all the samples.\n","    # This gives a perspective into the density and separation of the formed\n","    # clusters\n","    silhouette_avg = silhouette_score(X, cluster_labels)\n","    print(\"For n_clusters =\", n_clusters,\n","          \"The average silhouette_score is :\", silhouette_avg)\n","\n","    # Compute the silhouette scores for each sample\n","    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n","\n","    y_lower = 10\n","    for i in range(n_clusters):\n","        # Aggregate the silhouette scores for samples belonging to\n","        # cluster i, and sort them\n","        ith_cluster_silhouette_values = \\\n","            sample_silhouette_values[cluster_labels == i]\n","\n","        ith_cluster_silhouette_values.sort()\n","\n","        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n","        y_upper = y_lower + size_cluster_i\n","\n","        color = cm.nipy_spectral(float(i) / n_clusters)\n","        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n","                          0, ith_cluster_silhouette_values,\n","                          facecolor=color, edgecolor=color, alpha=0.7)\n","\n","        # Label the silhouette plots with their cluster numbers at the middle\n","        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n","\n","        # Compute the new y_lower for next plot\n","        y_lower = y_upper + 10  # 10 for the 0 samples\n","\n","    ax1.set_title(\"The silhouette plot for the various clusters.\")\n","    ax1.set_xlabel(\"The silhouette coefficient values\")\n","    ax1.set_ylabel(\"Cluster label\")\n","\n","    # The vertical line for average silhouette score of all the values\n","    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n","\n","    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n","    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n","\n","    # 2nd Plot showing the actual clusters formed\n","    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n","    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n","                c=colors, edgecolor='k')\n","\n","    # Labeling the clusters\n","    centers = clusterer.cluster_centers_\n","    # Draw white circles at cluster centers\n","    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n","                c=\"white\", alpha=1, s=200, edgecolor='k')\n","\n","    for i, c in enumerate(centers):\n","        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n","                    s=50, edgecolor='k')\n","\n","    ax2.set_title(\"The visualization of the clustered data.\")\n","    ax2.set_xlabel(\"Feature space for the 1st feature\")\n","    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n","\n","    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n","                  \"with n_clusters = %d\" % n_clusters),\n","                 fontsize=14, fontweight='bold')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["- The Silhouette score isn't significant for any cluster since its close to 0 for every k, that translates to less differentiability for a point to belong to a particular cluster.\n","- GMM can help in this case because animals share a lot of similar traits with each other in terms of appearance but we have to get the bottleneck case since an animal can only belong to one cluster, so kmeans will be the way to go but a different feature/keypoint detection might help identify right number of clusters."]},{"cell_type":"markdown","metadata":{},"source":["## Using SIFT/SURF/ORB technique"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def build_dictionary(xfeatures2d, images, n_clusters):\n","    #print('Computing descriptors..')        \n","    desc_list = []\n","    \n","    for image_path in images:\n","        image = cv2.imread(image_path)\n","        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        kp, dsc = xfeatures2d.detectAndCompute(gray, None)\n","        desc_list.extend(dsc)\n","\n","    desc = np.array(desc_list)\n","    #print('Creating BoW dictionary using K-Means clustering with k={}..'.format(n_clusters))\n","    dictionary = MiniBatchKMeans(n_clusters=n_clusters, batch_size=100, verbose=0)\n","    dictionary.fit(desc)\n","    \n","    distortion = sum(np.min(cdist(desc, dictionary.cluster_centers_, \n","                      'euclidean'),axis=1)) / desc.shape[0]\n","    \n","    return distortion"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["orb = cv2.ORB_create()\n","images = df.image.values\n","K = range(4,10)\n","distortions = []\n","\n","for k in tqdm(K):\n","    distortions.append(build_dictionary(orb, images, n_clusters=k))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.plot(K, distortions, 'bx-') \n","plt.xlabel('Values of K') \n","plt.ylabel('Distortion') \n","plt.title('The Elbow Method using Distortion') \n","plt.show() "]},{"cell_type":"markdown","metadata":{},"source":["- The ORB technique tells us there are 6/7 major clusters that are persistent in the data"]}],"metadata":{"kernelspec":{"display_name":"smbh","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"2b2b9eb080de1e8e3749ef78ba28bab8b399e68a25c693b25b861f9c2bf2b89c"}}},"nbformat":4,"nbformat_minor":4}
