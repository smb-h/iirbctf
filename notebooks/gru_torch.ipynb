{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_path = \"../data/clevr/CLEVR_CoGenT_v1.0/questions/\"\n",
    "train = json.load(open(dataset_base_path + \"CLEVR_trainA_questions.json\", \"r\"))\n",
    "validation = json.load(open(dataset_base_path + \"CLEVR_valA_questions.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699960\n",
      "150000\n"
     ]
    }
   ],
   "source": [
    "print(len(train[\"questions\"]))\n",
    "print(len(validation[\"questions\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_index': 301889,\n",
       " 'question_family_index': 58,\n",
       " 'image_index': 30189,\n",
       " 'question': 'The yellow block that is made of the same material as the large yellow thing is what size?',\n",
       " 'answer': 'small',\n",
       " 'image_filename': 'CLEVR_trainA_030189.png',\n",
       " 'split': 'trainA',\n",
       " 'program': [{'value_inputs': [], 'inputs': [], 'function': 'scene'},\n",
       "  {'value_inputs': ['large'], 'inputs': [0], 'function': 'filter_size'},\n",
       "  {'value_inputs': ['yellow'], 'inputs': [1], 'function': 'filter_color'},\n",
       "  {'value_inputs': [], 'inputs': [2], 'function': 'unique'},\n",
       "  {'value_inputs': [], 'inputs': [3], 'function': 'same_material'},\n",
       "  {'value_inputs': ['yellow'], 'inputs': [4], 'function': 'filter_color'},\n",
       "  {'value_inputs': ['cube'], 'inputs': [5], 'function': 'filter_shape'},\n",
       "  {'value_inputs': [], 'inputs': [6], 'function': 'unique'},\n",
       "  {'value_inputs': [], 'inputs': [7], 'function': 'query_size'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"questions\"][random.randint(0, len(train[\"questions\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {\"<PAD>\": 0}\n",
    "train_questions = []\n",
    "train_answers = []\n",
    "val_questions = []\n",
    "val_answers = []\n",
    "MAX_LENGTH = 0\n",
    "\n",
    "\n",
    "for q in train[\"questions\"]:\n",
    "    _q = q[\"question\"].replace(\"?\", \"\").replace(\".\", \"\").replace(\",\", \"\").split(\" \")\n",
    "    train_questions.append(_q)\n",
    "    train_answers.append(q[\"answer\"])\n",
    "    if len(_q) > MAX_LENGTH:\n",
    "        MAX_LENGTH = len(_q)\n",
    "    # question\n",
    "    for w in _q:\n",
    "        if w in vocab:\n",
    "            vocab[w] += 1\n",
    "        else:\n",
    "            vocab[w] = 1\n",
    "    # answer\n",
    "    for w in q[\"answer\"].split(\" \"):\n",
    "        if w in vocab:\n",
    "            vocab[w] += 1\n",
    "        else:\n",
    "            vocab[w] = 1\n",
    "    # inputs\n",
    "    for p in q[\"program\"]:\n",
    "        for _iv in p[\"value_inputs\"]:\n",
    "            if _iv in vocab:\n",
    "                vocab[_iv] += 1\n",
    "            else:\n",
    "                vocab[_iv] = 1\n",
    "        # functions\n",
    "        for w in p[\"function\"].split(\"_\"):\n",
    "            if w in vocab:\n",
    "                vocab[w] += 1\n",
    "            else:\n",
    "                vocab[w] = 1\n",
    "\n",
    "for q in validation[\"questions\"]:\n",
    "    _q = q[\"question\"].replace(\"?\", \"\").replace(\".\", \"\").replace(\",\", \"\").split(\" \")\n",
    "    val_questions.append(_q)\n",
    "    val_answers.append(q[\"answer\"])\n",
    "    if len(_q) > MAX_LENGTH:\n",
    "        MAX_LENGTH = len(_q)\n",
    "    # question\n",
    "    for w in _q:\n",
    "        if w in vocab:\n",
    "            vocab[w] += 1\n",
    "        else:\n",
    "            vocab[w] = 1\n",
    "    # answer\n",
    "    for w in q[\"answer\"].split(\" \"):\n",
    "        if w in vocab:\n",
    "            vocab[w] += 1\n",
    "        else:\n",
    "            vocab[w] = 1\n",
    "    # inputs\n",
    "    for p in q[\"program\"]:\n",
    "        for _iv in p[\"value_inputs\"]:\n",
    "            if _iv in vocab:\n",
    "                vocab[_iv] += 1\n",
    "            else:\n",
    "                vocab[_iv] = 1\n",
    "        # functions\n",
    "        for w in p[\"function\"].split(\"_\"):\n",
    "            if w in vocab:\n",
    "                vocab[w] += 1\n",
    "            else:\n",
    "                vocab[w] = 1\n",
    "vocab = list(set(vocab))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "# convert the input sentences to a tensor of indices\n",
    "for q in train_questions:\n",
    "    padded_q = q + [\"<PAD>\"] * (MAX_LENGTH - len(q))\n",
    "    # MAX_LENGTH * len(vocab)\n",
    "    x_train.append([vocab.index(w) for w in padded_q])\n",
    "\n",
    "for q in val_questions:\n",
    "    padded_q = q + [\"<PAD>\"] * (MAX_LENGTH - len(q))\n",
    "    x_val.append([vocab.index(w) for w in padded_q])\n",
    "\n",
    "# answers\n",
    "for a in train_answers:\n",
    "    y_train.append(vocab.index(a))\n",
    "for a in val_answers:\n",
    "    y_val.append(vocab.index(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "119\n",
      "[92, 23, 109, 115, 0, 2, 27, 53, 84, 78, 25, 53, 96, 114, 32, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49]\n"
     ]
    }
   ],
   "source": [
    "print(MAX_LENGTH)\n",
    "print(len(vocab))\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to torch tensors\n",
    "x_train = torch.tensor(x_train)\n",
    "y_train = torch.tensor(y_train)\n",
    "x_val = torch.tensor(x_val)\n",
    "y_val = torch.tensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([699960, 45])\n",
      "torch.Size([699960])\n",
      "torch.Size([150000, 45])\n",
      "torch.Size([150000])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bi-directional GRU model\n",
    "class BiGRU(nn.Module):\n",
    "    def __init__(self, vocab_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super(BiGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_dim, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_len, batch_size)\n",
    "        embedded = self.embedding(x)\n",
    "        # embedded shape: (seq_len, batch_size, embedding_dim)\n",
    "        output, hidden = self.gru(embedded)\n",
    "        # output shape: (seq_len, batch_size, hidden_dim * 2)\n",
    "        # hidden shape: (2, batch_size, hidden_dim)\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        # hidden shape: (batch_size, hidden_dim * 2)\n",
    "        out = self.fc(hidden)\n",
    "        # out shape: (batch_size, output_dim)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(set(train_answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiGRU(\n",
      "  (embedding): Embedding(119, 300)\n",
      "  (gru): GRU(300, 128, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=28, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions\n",
    "vocab_dim = len(vocab)  # the size of the vocabulary\n",
    "embedding_dim = 300  # the size of the embedding vector\n",
    "hidden_dim = 128\n",
    "output_dim = len(set(train_answers))\n",
    "\n",
    "model = BiGRU(vocab_dim, embedding_dim, hidden_dim, output_dim)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to GPU 1\n",
    "model = model.cuda(1)\n",
    "loss_fn = loss_fn.cuda(1)\n",
    "x_train = x_train.cuda(1)\n",
    "y_train = y_train.cuda(1)\n",
    "x_val = x_val.cuda(1)\n",
    "y_val = y_val.cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_MAPPING_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m x \u001b[39m=\u001b[39m x_train[i:i\u001b[39m+\u001b[39mbatch_size]\n\u001b[1;32m      9\u001b[0m y \u001b[39m=\u001b[39m y_train[i:i\u001b[39m+\u001b[39mbatch_size]\n\u001b[0;32m---> 10\u001b[0m y_pred \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     11\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_pred, y)\n\u001b[1;32m     12\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.venvs/gscmr4cqbir/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m, in \u001b[0;36mBiGRU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(x)\n\u001b[1;32m     12\u001b[0m \u001b[39m# embedded shape: (seq_len, batch_size, embedding_dim)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgru(embedded)\n\u001b[1;32m     14\u001b[0m \u001b[39m# output shape: (seq_len, batch_size, hidden_dim * 2)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# hidden shape: (2, batch_size, hidden_dim)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m hidden \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((hidden[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m,:,:], hidden[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:,:]), dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.venvs/gscmr4cqbir/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venvs/gscmr4cqbir/lib/python3.8/site-packages/torch/nn/modules/rnn.py:955\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    954\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    956\u001b[0m                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    957\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    959\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_MAPPING_ERROR"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 45\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        x = x_train[i:i+batch_size]\n",
    "        y = y_train[i:i+batch_size]\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1} Loss: {epoch_loss/len(x_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gscmr4cqbir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0eb280f2a99e787a1cb7c4382dc3dc8031a887c8fd3d22c9b74e1e2b688607e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
