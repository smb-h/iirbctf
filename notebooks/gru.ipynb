{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchtext\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super(BiGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text: [seq_len, batch_size]\n",
    "        embedded = self.embedding(text) # [seq_len, batch_size, embedding_dim]\n",
    "        embedded = self.dropout(embedded)\n",
    "        hidden, _ = self.gru(embedded) # [seq_len, batch_size, hidden_dim*2]\n",
    "        # Concatenate the forward and backward hidden states\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1) # [batch_size, hidden_dim*2]\n",
    "        out = self.fc(hidden) # [batch_size, output_dim]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_path = \"../data/clevr/CLEVR_CoGenT_v1.0/questions/\"\n",
    "x_train = json.load(open(dataset_base_path + \"CLEVR_trainA_questions.json\", \"r\"))\n",
    "x_val = json.load(open(dataset_base_path + \"CLEVR_valA_questions.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699960"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[\"questions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_index': 476847,\n",
       " 'question_family_index': 10,\n",
       " 'image_index': 47687,\n",
       " 'question': 'Is the tiny shiny block the same color as the tiny matte ball?',\n",
       " 'answer': 'no',\n",
       " 'image_filename': 'CLEVR_trainA_047687.png',\n",
       " 'split': 'trainA',\n",
       " 'program': [{'value_inputs': [], 'inputs': [], 'function': 'scene'},\n",
       "  {'value_inputs': ['small'], 'inputs': [0], 'function': 'filter_size'},\n",
       "  {'value_inputs': ['metal'], 'inputs': [1], 'function': 'filter_material'},\n",
       "  {'value_inputs': ['cube'], 'inputs': [2], 'function': 'filter_shape'},\n",
       "  {'value_inputs': [], 'inputs': [3], 'function': 'unique'},\n",
       "  {'value_inputs': [], 'inputs': [], 'function': 'scene'},\n",
       "  {'value_inputs': ['small'], 'inputs': [5], 'function': 'filter_size'},\n",
       "  {'value_inputs': ['rubber'], 'inputs': [6], 'function': 'filter_material'},\n",
       "  {'value_inputs': ['sphere'], 'inputs': [7], 'function': 'filter_shape'},\n",
       "  {'value_inputs': [], 'inputs': [8], 'function': 'unique'},\n",
       "  {'value_inputs': [], 'inputs': [4], 'function': 'query_color'},\n",
       "  {'value_inputs': [], 'inputs': [9], 'function': 'query_color'},\n",
       "  {'value_inputs': [], 'inputs': [10, 11], 'function': 'equal_color'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[\"questions\"][random.randint(0, len(x_train[\"questions\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for question in x_train[\"questions\"]:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gscmr4cqbir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0eb280f2a99e787a1cb7c4382dc3dc8031a887c8fd3d22c9b74e1e2b688607e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
